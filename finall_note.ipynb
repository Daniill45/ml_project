{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2202b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r req.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psycopg2\n",
    "import os\n",
    "import datetime\n",
    "from dotenv import load_dotenv  \n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import TargetEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e892ec99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { font-size:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "display(HTML(\"<style>.container { font-size:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0892cf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387cbdf9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NoSuchModuleError",
     "evalue": "Can't load plugin: sqlalchemy.dialects:postgresql",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchModuleError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m post_text_df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43;03m\"\"\"SELECT * FROM public.post_text_df \"\"\"\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgresql://robot-startml-ro:pheiph0hahj1Vaif@\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgres.lab.karpov.courses:6432/startml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m post_text_df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:599\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_sql\u001b[39m(\n\u001b[1;32m    476\u001b[0m     sql,\n\u001b[1;32m    477\u001b[0m     con,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    483\u001b[0m     chunksize: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    484\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m    Read SQL query or database table into a DataFrame.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m    1           1  2010-11-12\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 599\u001b[0m     pandas_sql \u001b[38;5;241m=\u001b[39m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    603\u001b[0m             sql,\n\u001b[1;32m    604\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m             chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    609\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:786\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[0;34m(con, schema, meta, is_cursor)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;124;03mConvenience function to return the correct PandasSQL subclass based on the\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;124;03mprovided parameters.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m# When support for DBAPI connections is removed,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;66;03m# is_cursor should not be necessary.\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m con \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_sqlalchemy_connectable(con):\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SQLDatabase(con, schema\u001b[38;5;241m=\u001b[39mschema, meta\u001b[38;5;241m=\u001b[39mmeta)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:771\u001b[0m, in \u001b[0;36m_engine_builder\u001b[0;34m(con)\u001b[0m\n\u001b[1;32m    769\u001b[0m         _SQLALCHEMY_INSTALLED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m         con \u001b[38;5;241m=\u001b[39m \u001b[43msqlalchemy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m con\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m con\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py:309\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    303\u001b[0m         _warn_with_version(\n\u001b[1;32m    304\u001b[0m             messages[m],\n\u001b[1;32m    305\u001b[0m             versions[m],\n\u001b[1;32m    306\u001b[0m             version_warnings[m],\n\u001b[1;32m    307\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    308\u001b[0m         )\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/create.py:534\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m u \u001b[38;5;241m=\u001b[39m _url\u001b[38;5;241m.\u001b[39mmake_url(url)\n\u001b[1;32m    532\u001b[0m u, plugins, kwargs \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39m_instantiate_plugins(kwargs)\n\u001b[0;32m--> 534\u001b[0m entrypoint \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_entrypoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m dialect_cls \u001b[38;5;241m=\u001b[39m entrypoint\u001b[38;5;241m.\u001b[39mget_dialect_cls(u)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_coerce_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/url.py:661\u001b[0m, in \u001b[0;36mURL._get_entrypoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    660\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrivername\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 661\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# check for legacy dialects that\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# would return a module with 'dialect' as the\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# actual class\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdialect, \u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdialect, Dialect)\n\u001b[1;32m    669\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py:343\u001b[0m, in \u001b[0;36mPluginLoader.load\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimpls[name] \u001b[38;5;241m=\u001b[39m impl\u001b[38;5;241m.\u001b[39mload\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mNoSuchModuleError(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load plugin: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup, name)\n\u001b[1;32m    345\u001b[0m )\n",
      "\u001b[0;31mNoSuchModuleError\u001b[0m: Can't load plugin: sqlalchemy.dialects:postgresql"
     ]
    }
   ],
   "source": [
    "# Подключаемся к бд(уже неактивно)\n",
    "post_text_df=pd.read_sql(\n",
    "    \"\"\"SELECT * FROM public.post_text_df \"\"\",\n",
    "    \n",
    "    con=\"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "        \"postgres.lab.karpov.courses:6432/startml\"\n",
    ")\n",
    "\n",
    "post_text_df # Информация о постах, которые будем рекомендовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b9a5a4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NoSuchModuleError",
     "evalue": "Can't load plugin: sqlalchemy.dialects:postgresql",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchModuleError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user_data\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43;03m\"\"\"SELECT * FROM public.user_data \"\"\"\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgresql://robot-startml-ro:pheiph0hahj1Vaif@\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgres.lab.karpov.courses:6432/startml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m user_data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:599\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_sql\u001b[39m(\n\u001b[1;32m    476\u001b[0m     sql,\n\u001b[1;32m    477\u001b[0m     con,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    483\u001b[0m     chunksize: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    484\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m    Read SQL query or database table into a DataFrame.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m    1           1  2010-11-12\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 599\u001b[0m     pandas_sql \u001b[38;5;241m=\u001b[39m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    603\u001b[0m             sql,\n\u001b[1;32m    604\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m             chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    609\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:786\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[0;34m(con, schema, meta, is_cursor)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;124;03mConvenience function to return the correct PandasSQL subclass based on the\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;124;03mprovided parameters.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m# When support for DBAPI connections is removed,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;66;03m# is_cursor should not be necessary.\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m con \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_sqlalchemy_connectable(con):\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SQLDatabase(con, schema\u001b[38;5;241m=\u001b[39mschema, meta\u001b[38;5;241m=\u001b[39mmeta)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:771\u001b[0m, in \u001b[0;36m_engine_builder\u001b[0;34m(con)\u001b[0m\n\u001b[1;32m    769\u001b[0m         _SQLALCHEMY_INSTALLED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m         con \u001b[38;5;241m=\u001b[39m \u001b[43msqlalchemy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m con\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m con\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py:309\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    303\u001b[0m         _warn_with_version(\n\u001b[1;32m    304\u001b[0m             messages[m],\n\u001b[1;32m    305\u001b[0m             versions[m],\n\u001b[1;32m    306\u001b[0m             version_warnings[m],\n\u001b[1;32m    307\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    308\u001b[0m         )\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/create.py:534\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m u \u001b[38;5;241m=\u001b[39m _url\u001b[38;5;241m.\u001b[39mmake_url(url)\n\u001b[1;32m    532\u001b[0m u, plugins, kwargs \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39m_instantiate_plugins(kwargs)\n\u001b[0;32m--> 534\u001b[0m entrypoint \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_entrypoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m dialect_cls \u001b[38;5;241m=\u001b[39m entrypoint\u001b[38;5;241m.\u001b[39mget_dialect_cls(u)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_coerce_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/url.py:661\u001b[0m, in \u001b[0;36mURL._get_entrypoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    660\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrivername\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 661\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# check for legacy dialects that\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# would return a module with 'dialect' as the\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# actual class\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdialect, \u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdialect, Dialect)\n\u001b[1;32m    669\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py:343\u001b[0m, in \u001b[0;36mPluginLoader.load\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimpls[name] \u001b[38;5;241m=\u001b[39m impl\u001b[38;5;241m.\u001b[39mload\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mNoSuchModuleError(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load plugin: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup, name)\n\u001b[1;32m    345\u001b[0m )\n",
      "\u001b[0;31mNoSuchModuleError\u001b[0m: Can't load plugin: sqlalchemy.dialects:postgresql"
     ]
    }
   ],
   "source": [
    "user_data=pd.read_sql(\n",
    "    \"\"\"SELECT * FROM public.user_data \"\"\",\n",
    "    \n",
    "    con=\"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "        \"postgres.lab.karpov.courses:6432/startml\"\n",
    ")\n",
    "\n",
    "user_data # Информация о пользователях в бд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a274a5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NoSuchModuleError",
     "evalue": "Can't load plugin: sqlalchemy.dialects:postgresql",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchModuleError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feed_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43;03m\"\"\"SELECT * FROM public.feed_data LIMIT 100000\"\"\"\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgresql://robot-startml-ro:pheiph0hahj1Vaif@\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpostgres.lab.karpov.courses:6432/startml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m feed_data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:599\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_sql\u001b[39m(\n\u001b[1;32m    476\u001b[0m     sql,\n\u001b[1;32m    477\u001b[0m     con,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    483\u001b[0m     chunksize: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    484\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m    Read SQL query or database table into a DataFrame.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m    1           1  2010-11-12\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 599\u001b[0m     pandas_sql \u001b[38;5;241m=\u001b[39m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    603\u001b[0m             sql,\n\u001b[1;32m    604\u001b[0m             index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m             chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    609\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:786\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[0;34m(con, schema, meta, is_cursor)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;124;03mConvenience function to return the correct PandasSQL subclass based on the\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;124;03mprovided parameters.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m# When support for DBAPI connections is removed,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;66;03m# is_cursor should not be necessary.\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m con \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_sqlalchemy_connectable(con):\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SQLDatabase(con, schema\u001b[38;5;241m=\u001b[39mschema, meta\u001b[38;5;241m=\u001b[39mmeta)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:771\u001b[0m, in \u001b[0;36m_engine_builder\u001b[0;34m(con)\u001b[0m\n\u001b[1;32m    769\u001b[0m         _SQLALCHEMY_INSTALLED \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m         con \u001b[38;5;241m=\u001b[39m \u001b[43msqlalchemy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m con\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m con\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py:309\u001b[0m, in \u001b[0;36mdeprecated_params.<locals>.decorate.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    303\u001b[0m         _warn_with_version(\n\u001b[1;32m    304\u001b[0m             messages[m],\n\u001b[1;32m    305\u001b[0m             versions[m],\n\u001b[1;32m    306\u001b[0m             version_warnings[m],\n\u001b[1;32m    307\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    308\u001b[0m         )\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/create.py:534\u001b[0m, in \u001b[0;36mcreate_engine\u001b[0;34m(url, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m u \u001b[38;5;241m=\u001b[39m _url\u001b[38;5;241m.\u001b[39mmake_url(url)\n\u001b[1;32m    532\u001b[0m u, plugins, kwargs \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39m_instantiate_plugins(kwargs)\n\u001b[0;32m--> 534\u001b[0m entrypoint \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_entrypoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m dialect_cls \u001b[38;5;241m=\u001b[39m entrypoint\u001b[38;5;241m.\u001b[39mget_dialect_cls(u)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_coerce_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/url.py:661\u001b[0m, in \u001b[0;36mURL._get_entrypoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    660\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrivername\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 661\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# check for legacy dialects that\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# would return a module with 'dialect' as the\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# actual class\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdialect, \u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdialect, Dialect)\n\u001b[1;32m    669\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py:343\u001b[0m, in \u001b[0;36mPluginLoader.load\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimpls[name] \u001b[38;5;241m=\u001b[39m impl\u001b[38;5;241m.\u001b[39mload\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mNoSuchModuleError(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load plugin: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup, name)\n\u001b[1;32m    345\u001b[0m )\n",
      "\u001b[0;31mNoSuchModuleError\u001b[0m: Can't load plugin: sqlalchemy.dialects:postgresql"
     ]
    }
   ],
   "source": [
    "feed_data = pd.read_sql(\n",
    "    \"\"\"SELECT * FROM public.feed_data LIMIT 100000\"\"\",\n",
    "    \n",
    "    con=\"postgresql://robot-startml-ro:pheiph0hahj1Vaif@\"\n",
    "        \"postgres.lab.karpov.courses:6432/startml\"\n",
    ")\n",
    "\n",
    "feed_data # Информация о действиях пользователей(просмотр/лайк)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce858732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список стран пользователей\n",
    "countries=list(user_data.country.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\sa-zA-Z0-9@\\[\\]]',' ',text) # Удаляет пунктцацию\n",
    "    text = re.sub(r'\\w*\\d+\\w*', '', text) # Удаляет цифры\n",
    "    text = re.sub(' ', \"\", text) # Удаляет ненужные пробелы\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание датасета с выходными\n",
    "def create_holiday_dataset():\n",
    "    holiday=pd.read_csv(\".../yourpath/holiday_calendar.csv\")# Нужно добавить признак выходного дня, выходной либо выходной день недели, либо праздник\n",
    "    holiday.Date=pd.to_datetime(holiday.Date)\n",
    "    holiday[\"newdate\"]=holiday.Date.apply(lambda x:f\"2021-{x.month}-{x.day}\")\n",
    "    holiday[\"newdate\"]=pd.to_datetime(holiday.newdate)\n",
    "    holiday=holiday[holiday.Country.apply(lambda x:x.title() in countries)]\n",
    "    holiday=holiday[(holiday.Type=='National Holiday')]\n",
    "    holiday=holiday[[\"Country\",\"newdate\"]]\n",
    "    holiday=holiday[(holiday.newdate>=feed_data.timestamp.min())&(holiday.newdate<=feed_data.timestamp.max())]\n",
    "    return holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dict():\n",
    "    holidays_dict={}\n",
    "    for i in holiday.values:\n",
    "        if i[0].title() not in holidays_dict:\n",
    "            a=i[0].title()\n",
    "            holidays_dict[a]=[i[1]]\n",
    "        else:\n",
    "            a=i[0].title()\n",
    "            holidays_dict[a].append(i[1])\n",
    "    holidays_dict['Finland']=[]\n",
    "    return holidays_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0330277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weeknd(new_table1):\n",
    "    holiday=create_holiday_dataset()\n",
    "    holidays_dict=create_dict()\n",
    "    new_table1[\"weekend\"]=0# Создаем признак выходного дня\n",
    "    for i in range(new_table1.shape[0]):\n",
    "        time=holidays_dict[new_table1.country[i]]\n",
    "        for j in time:\n",
    "            if j.month==new_table1.timestamp[i].month and j.day==new_table1.timestamp[i].day:\n",
    "                new_table1.weekend[i]=1 # Выходной день есть в датасете\n",
    "        if new_table1.day[i]==5 or new_table1.day[i]==6:\n",
    "            new_table1.weekend[i]=1 # Суббота или воскресенье\n",
    "    return new_table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработаем feed_data\n",
    "def prepare_feed(feed_data):\n",
    "    feed_data=feed_data[feed_data.action==\"view\"]\n",
    "    feed_data=feed_data.drop(\"action\",axis=1)\n",
    "    feed_data[\"day_of_week\"]=pd.DatetimeIndex(feed_data['timestamp']).day_of_week # Признак дня недели\n",
    "    feed_data[\"month\"]=pd.DatetimeIndex(feed_data['timestamp']).month\n",
    "    feed_data[\"hour\"]=pd.DatetimeIndex(feed_data['timestamp']).hour\n",
    "    feed_data[\"day\"]=pd.DatetimeIndex(feed_data['timestamp']).day\n",
    "    return feed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.city.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084fdb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВВП по странам\n",
    "gdp={'Russia':32803, 'Ukraine':14220, 'Belarus':21699, 'Azerbaijan':15843, 'Kazakhstan':28600,\n",
    "       'Finland':53654, 'Turkey':30472, 'Latvia':34469, 'Cyprus':42556, 'Switzerland':77324, 'Estonia':42192}\n",
    "def city_exist(x,a):\n",
    "    if x in a:\n",
    "        return x\n",
    "    return \"no_city\"\n",
    "def prepare_user(user_data):\n",
    "    world_cities=pd.read_csv(\"/yourpath/worldcities.csv\") # Датасет городов мира\n",
    "    countries=list(user_data.country.unique())\n",
    "    world_cities=world_cities[world_cities.country.apply(lambda x: x in countries)] # Оставляем только нужные страны\n",
    "    world_cities=world_cities[[\"city\",\"lat\",\"lng\",\"country\",\"population\",\"admin_name\",\"capital\"]]\n",
    "    user_data.city=user_data.city.apply(lambda x:clean_text(x))\n",
    "    world_cities.city=world_cities.city.apply(lambda x:clean_text(x)) # Приводим названия городов к единому виду\n",
    "    a=set(world_cities.city)\n",
    "    user_data.city=user_data.city.apply(lambda x:city_exist(x,a)) # функция вовращает есть ли такой город в списке или нет\n",
    "    user_data=user_data[user_data.city!=\"no_city\"]\n",
    "    user_data=user_data.merge(world_cities, how='left', left_on='city', right_on='city').drop([\"country_y\"],axis=1)\n",
    "    user_data.admin_name.fillna(user_data.city,inplace=True)\n",
    "    user_data[\"is_capital\"]=0 # Живет ли человек в столице\n",
    "    user_data.loc[user_data.capital=='primary',\"is_capital\"]=1\n",
    "    user_data=user_data.drop([\"lat\",\"lng\",\"capital\"],axis=1)\n",
    "    user_data=user_data.rename({\"country_x\":\"country\"},axis=1)\n",
    "    user_data[\"parity_gdp\"]=user_data.country.apply(lambda x:gdp[x])\n",
    "    return user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_post(post_text_df):\n",
    "\n",
    "\n",
    "    vectorizer = TfidfVectorizer() # Возьмем максимум и среднее tfidf как признак\n",
    "    ps=PorterStemmer() # Находим основу слова\n",
    "    words=[]\n",
    "    for word in post_text_df.text[0].split():\n",
    "        words.append(ps.stem(word))\n",
    "    text = vectorizer.fit_transform(post_text_df.text)\n",
    "    max_tfidf=[]\n",
    "    mean_tfidf=[]\n",
    "    tt=text.toarray()\n",
    "    for i in range(len(tt)):\n",
    "        mean_tfidf.append(np.mean(tt[i]))\n",
    "        max_tfidf.append(max(tt[i]))\n",
    "    post_text_df[\"mean_tf_idf_2\"]=mean_tfidf\n",
    "    post_text_df[\"max_tf_idf_2\"]=max_tfidf\n",
    "    lenght=[]\n",
    "    for i in post_text_df.text:\n",
    "        lenght.append(len(i))\n",
    "    post_text_df[\"lenght_text\"]=lenght\n",
    "    #post_text_df_2=post_text_df.drop([\"text\"],axis=1)\n",
    "    \n",
    "    return post_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5542ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим таблицу\n",
    "def create_table():\n",
    "    global post_text_df,feed_data,user_data\n",
    "    feed_data=prepare_feed(feed_data)\n",
    "    print(\"feed_ready\")\n",
    "    user_data=prepare_user(user_data)\n",
    "    print(\"user_ready\")\n",
    "    post_text_df=prepare_post(post_text_df)\n",
    "    print(\"post_ready\")\n",
    "    new_table=user_data.merge(feed_data, how='left', left_on='user_id', right_on='user_id')\n",
    "    new_table=new_table.merge(post_text_df, how='left', left_on='post_id', right_on='post_id')\n",
    "    #new_table=new_table[~new_table.post_id.isna()]\n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af9f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишем кастомный трансформер, чтобы он автоматически применял mean target encoding/one hot encoding\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import itertools\n",
    "\n",
    "class CustomFunctionTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 object_columns=[],\n",
    "                 target_name='target'):\n",
    "        \n",
    "        self.object_columns = object_columns\n",
    "        self.target_name = target_name\n",
    "        \n",
    "                \n",
    "    def fit(self,\n",
    "            X,\n",
    "            y):\n",
    "        \n",
    "        X_fit = X.copy()\n",
    "        y_fit = y.copy()\n",
    "\n",
    "        self.numeric_columns = [x for x in X_fit.columns if x not in self.object_columns]\n",
    "        \n",
    "        X_with_target = pd.concat((X_fit, y_fit), axis=1)\n",
    "        \n",
    "        # Сгенерим колонки к которым применим One-Hot-Encoding\n",
    "        self.cols_for_ohe = [col for col in self.object_columns\n",
    "                             if \n",
    "                             X_with_target[col].nunique() <= 13]\n",
    "        \n",
    "        # Запомним все ohe колонки и их названия!\n",
    "        self.ohe_names = {col : sorted([f\"{col}_{value}\" for value in X_with_target[col].unique()])\n",
    "                          for col in self.cols_for_ohe}\n",
    "        \n",
    "        \n",
    "        # Сгенерим колонки к которым применим Mean-Target-Encoding\n",
    "        self.cols_for_mte = [col for col in self.object_columns\n",
    "                             if X_with_target[col].nunique() > 13]\n",
    "        \n",
    "        # Посчитаем на валидации средние значения таргета+ шум\n",
    "        self.dict_of_means = {col : X_with_target.groupby(col)[self.target_name].mean() + 0.006*np.random.randn() \n",
    "                              for col in self.cols_for_mte}\n",
    "        \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self,\n",
    "                  X,\n",
    "                  y=None):\n",
    "        \n",
    "        X_ = X.copy()\n",
    "        \n",
    "        \n",
    "        data_part = pd.get_dummies(X_[self.cols_for_ohe],\n",
    "                                   prefix=self.cols_for_ohe)\n",
    "        \n",
    "        data_part_cols = data_part.columns\n",
    "        \n",
    "        X_ = X_.drop(self.cols_for_ohe, axis=1)\n",
    "        X_ = pd.concat((X_, data_part), axis=1)\n",
    "        \n",
    "    \n",
    "        for col in self.cols_for_mte:\n",
    "                X_[col] = X_[col].map(self.dict_of_means[col])\n",
    "                \n",
    "                mean_value = self.dict_of_means[col].values.mean()\n",
    "                \n",
    "                X_[col] = X_[col].fillna(mean_value)# заполняем значения которых нет в тесте средним\n",
    "                \n",
    "            \n",
    "            \n",
    "        all_ohe = list(itertools.chain(*list(self.ohe_names.values())))\n",
    "        \n",
    "        missing_columns = [x \n",
    "                           for x in all_ohe\n",
    "                           if x not in X_.columns\n",
    "                           and\n",
    "                           x not in self.numeric_columns]\n",
    "\n",
    "        extra_columns = [x\n",
    "                         for x in data_part_cols\n",
    "                         if x not in all_ohe]\n",
    "        \n",
    "        # Новые категории необходимо убрать\n",
    "        X_ = X_.drop(extra_columns, axis=1)\n",
    "    \n",
    "        # Отсутствующие категории (бинарные колонки)\n",
    "        # необходимо добавить: заполним их просто нулями\n",
    "        \n",
    "        if len(missing_columns) != 0:\n",
    "\n",
    "            zeros = np.zeros((X_.shape[0], len(missing_columns)))\n",
    "            zeros = pd.DataFrame(zeros,\n",
    "                                 columns=missing_columns,\n",
    "                                 index=X_.index)\n",
    "\n",
    "            X_ = pd.concat((X_, zeros), axis=1)\n",
    "            \n",
    "        return X_[sorted(X_.columns)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_post_text=pd.read_csv(\"/yourpath/embeddings_post_text\",index_col=0) # Эмбеддинги для текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_text_df=pd.concat([embeddings_post_text,post_text_df.text],axis=1) # Соединяем эмбединги и изначальные данные о постах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaef64a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_table1=create_table() # Создаем таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae150351",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59997f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=list(new_table1.loc[:,new_table1.dtypes==object].columns)\n",
    "numeric=list(new_table1.loc[:,new_table1.dtypes!=object].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539201a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table1[numeric] = new_table1[numeric].fillna(new_table1[numeric].median()) # заполняем медианой вещественные признаки\n",
    "new_table1[categorical] = new_table1[categorical].fillna(new_table1[categorical].mode().iloc[0]) # заполняем самым популярным значением кат-ые признаки \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc553824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if x in new_dict.keys():\n",
    "        return new_dict[x]\n",
    "    return 0\n",
    "def trans(X):\n",
    "    X[\"os\"]=X.os.apply(lambda x: 1 if x==\"iOS\" else 0)\n",
    "    X[\"source\"]=X.source.apply(lambda x: 1 if x==\"ads\" else 0)\n",
    "    X=pd.get_dummies(X,columns=['country','topic'])\n",
    "    \n",
    "    columns_dummies=['country_Azerbaijan', 'country_Belarus', 'country_Cyprus',\n",
    "       'country_Estonia', 'country_Finland', 'country_Kazakhstan',\n",
    "       'country_Latvia', 'country_Russia', 'country_Switzerland',\n",
    "       'country_Turkey', 'country_Ukraine', 'topic_business', 'topic_covid',\n",
    "       'topic_entertainment', 'topic_movie', 'topic_politics', 'topic_sport',\n",
    "       'topic_tech']\n",
    "    X[list(set(columns_dummies)-set(X.columns))]=0\n",
    "    return X[['user_id', 'gender', 'age', 'exp_group', 'os', 'source',\n",
    "       'population', 'admin_name', 'is_capital', 'parity_gdp',\n",
    "       'post_id', 'target', 'day_of_week', 'month', 'hour', 'year', 'day',\n",
    "        'DistanceToCluster_0', 'DistanceToCluster_1',\n",
    "       'DistanceToCluster_2', 'DistanceToCluster_3', 'DistanceToCluster_4',\n",
    "       'DistanceToCluster_5', 'DistanceToCluster_6', 'DistanceToCluster_7',\n",
    "       'DistanceToCluster_8', 'DistanceToCluster_9', 'DistanceToCluster_10',\n",
    "       'DistanceToCluster_11', 'DistanceToCluster_12', 'DistanceToCluster_13',\n",
    "       'DistanceToCluster_14', 'DistanceToCluster_15', 'DistanceToCluster_16',\n",
    "       'DistanceToCluster_17', 'DistanceToCluster_18', 'DistanceToCluster_19',\n",
    "       'DistanceToCluster_20', 'DistanceToCluster_21', 'DistanceToCluster_22',\n",
    "       'DistanceToCluster_23', 'DistanceToCluster_24', 'mean_tf_idf_2',\n",
    "       'max_tf_idf_2', 'lenght_text','country_Azerbaijan', 'country_Belarus', 'country_Cyprus',\n",
    "       'country_Estonia', 'country_Finland', 'country_Kazakhstan',\n",
    "       'country_Latvia', 'country_Russia', 'country_Switzerland',\n",
    "       'country_Turkey', 'country_Ukraine', 'topic_business', 'topic_covid',\n",
    "       'topic_entertainment', 'topic_movie', 'topic_politics', 'topic_sport',\n",
    "       'topic_tech']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d50155",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table1=new_table1.drop([\"timestamp\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=new_table1.target\n",
    "X=new_table1.drop([\"target\"],axis=1)\n",
    "categorical=list(X.loc[:,new_table1.dtypes==object].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c8ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"custom_transformer\",\n",
    "                  CustomFunctionTransformer(categorical,target_name=\"target\")),\n",
    "                 (\"cat\", \n",
    "                     CatBoostClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a2813",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"iterations\":[200],\"learning_rate\":[0.1],\"depth\":[7]} # Выбираем лучшие прааметры(оставил только оптимальные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2151c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c3b6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'Качество модели на трейне: {roc_auc_score(y_train, pipe.predict_proba(X_train)[:, 1])}')\n",
    "print(f'Качество модели на тесте: {roc_auc_score(y_test, pipe.predict_proba(X_test)[:, 1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d92972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat=CatBoostClassifier(random_seed=1,iterations=200,learning_rate=0.1,depth=7,cat_features=categorical,ignored_features=[\"post_id\",\"user_id\",\"source\",\"os\",\"text\"])\n",
    "cat.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c530f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Смотрим на roc_auc, потому что нам важно правильно оценивать вероятность того, что пользователь лайкнет пост\n",
    "print(f'Качество модели на трейне: {roc_auc_score(y_train, cat.predict_proba(X_train)[:, 1])}') \n",
    "print(f'Качество модели на тесте: {roc_auc_score(y_test, cat.predict_proba(X_test)[:, 1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "    \n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    \n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "    \n",
    "plot_feature_importance(cat.feature_importances_,X_train.columns,'Catboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b471fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.save_model('11catboost_model',\n",
    "                           format=\"cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_info.to_sql(    \n",
    "   \"posts_info_features\",                    \n",
    "    con=\"postgresql://username:password@host:port/database\",                      \n",
    "    schema=\"public\",                   \n",
    "    if_exists='replace'            \n",
    "   )                               \n",
    "                                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
